# 알고리즘 -> 학습 모델 (모두 클래스)
# 스케일러 / 인코딩 -> 전처리 기능
# 어떤 클래스로 인스턴스를 만들었느냐에 따라서 fit()의 기능이 다름
#---------------------------------------------> 객체 인스턴스로 만들기

# 알고리즘으로 만든 인스턴스일 경우
# 객체/인스턴스 = 클래스명() 만들기
# fit(2D문제, 1D정답)를 사용함 -> 학습진행 : 알고리즘 마다 확습 과정은 다를 수 있다


# 만약에 스캐일러를 만든다
# 스캐일러 객체/인스턴스 = 클래스()
# fit(2D수치피쳐) -> 수치 값 범위 설정을 위한 준비를 위해 한다
# 데이터 기반의 수치 계산 값을 해놓음
# transform() -> 변환

# KNN은 거리를 재는게 다임

# Feature Selection
# Filtering 방법 -> 타겟/종속변수에 관련성이 높은 피쳐/독립변수 선택하기
# 상관계수 보기 corr()
# 몇개를 선택할것인가? 
# 성능이 떨어질 때 관련성 높은 피쳐를 하나씩 더 늘려줘야함

#wrapper 방법
# Forward 방식 : 기준에 따라 K개 피쳐를 선택 -> 성능평가 -> 피쳐 추가
# Backward방식 : 모든 피쳐 선택 -> 성능평가 -> 피쳐제거(상관관계가 없는 피쳐)
# Step-Wide 방식 : Forward + Backward

# Embedding 방법 (지도학습모델)
# 모델 내부에 피쳐 선택 기능 포함됨 -> Important Feature, 주성분분석(PCA)

# Tunning -> 모델 수정
# 목적 : 모델의 성능을 높이기
# scikit-learn에서 모델 인스턴스의 score 메서드
# 모델 평가기준이 되는 성능지표 -> 분류/회귀에 따라 다름
# 회귀는 오차가 작을 수록 좋다.
# 결정계수 R2는 높을 수록 좋다.

# 모델 성능에 영향을 미치는 매개변수 -> Hyper_parameter
# KNN -> 최적의 K갯수
# LinearRegression -> 가중치, 기울기 초기화 값, 규제
# 학습 알고리즘마다 Hyper-parameter가 다름!

# 피쳐 제어
# 피쳐 갯수 조절 (추가 or 삭제)
# 피쳐 추출/압축

#AutoML -> 자동으로 하이퍼파라메터를 찾아줌. 돈내야함.

#기계학습
# 데이터기반을 규칙/패턴을 찾는 과정 -> 수식으로 바꾸기 -> 모델이라고 명칭
# 데이터를 기반으로 미래를 정확하게 예측할라고 기계학습을 하는 거임.

# 그래서 학습용 데이터셋과 테스트셋으로 나누는것임
# 학습용에서 잘나온걸 테스트에서도 잘나오게 일반화 시키려고 하는 것이 머신러닝의 목적

# 과대적합이냐 과소적합이냐를 판단해서 방법을 찾아야함. 이것을 Tunning이라고 함.
# 과대적합을 해결하기 위해 교차검증이라는 것을 함. (데이터가 적을 때 교차검증하는게 좋음)

# ML Process
# 1. 데이터준비 -> 데이터 로딩, 데이터확인
# 2. 데이터 전처리
# 정제(결측치, 중복값, 이상치, 컬럼 고유값)
# 피쳐에 대한 처리 (인코딩, 스케일링)
# 피쳐 선택, 가공
# 피쳐와 타겟(독립변수와 종속변수)

# 3. 학습준비 -> 데이터셋(train, validation, test) 
#     -> 데이터 부족 및 일반화를 위해서 train, test 데이터셋 분리
# 4. 학습진행
#     -> 교차검증으로 학습 진행 ; train 데이터셋 사용

# 5. 모델평가
# test 데이터로 평가 진행
# 평가기준 : 분류와 회귀는 다름.

### 모델의 성능을 높이는 튜닝 작업 필요
# Hyper parameter 제어 : 모델 인스턴스 생성 시 매개변수로 설정함
# 새로운 모델로 학습진행 -> 평가 -> 튜닝작업 -> a -> b -> c -> a ... 모델이 완벽할 때 까지 반복....



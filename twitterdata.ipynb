{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KDP-26\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KDP-26\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\KDP-26\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')  # 불용어 리스트 다운로드\n",
    "nltk.download('punkt')      # 토크나이저 데이터 다운로드\n",
    "nltk.download('wordnet')    # 표제어 추출(lemmatization)을 위한 WordNet 데이터 다운로드\n",
    "\n",
    "# 모듈 로딩\n",
    "# 모델관련 모듈\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import F1Score, BinaryF1Score\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date      flag  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1599995          4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996          4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997          4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998          4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999          4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE = 'training.1600000.processed.noemoticon.csv'\n",
    "# ISO-8859-1 또는 latin1 인코딩으로 파일 읽기\n",
    "df = pd.read_csv(FILE, encoding='ISO-8859-1', header=None)\n",
    "df.columns = ['sentiment', 'id', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   sentiment  1600000 non-null  int64 \n",
      " 1   id         1600000 non-null  int64 \n",
      " 2   date       1600000 non-null  object\n",
      " 3   flag       1600000 non-null  object\n",
      " 4   user       1600000 non-null  object\n",
      " 5   text       1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "id           0\n",
       "date         0\n",
       "flag         0\n",
       "user         0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "id           0\n",
       "date         0\n",
       "flag         0\n",
       "user         0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   sentiment  1600000 non-null  int64 \n",
      " 1   id         1600000 non-null  int64 \n",
      " 2   date       1600000 non-null  object\n",
      " 3   flag       1600000 non-null  object\n",
      " 4   user       1600000 non-null  object\n",
      " 5   text       1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "0                0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1                0  is upset that he can't update his Facebook by ...\n",
       "2                0  @Kenichan I dived many times for the ball. Man...\n",
       "3                0    my whole body feels itchy and like its on fire \n",
       "4                0  @nationwideclass no, it's not behaving at all....\n",
       "...            ...                                                ...\n",
       "1599995          4  Just woke up. Having no school is the best fee...\n",
       "1599996          4  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997          4  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998          4  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999          4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['sentiment', 'text']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-26\\AppData\\Local\\Temp\\ipykernel_8048\\3267886552.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=df, x='sentiment', palette=[colors[7], colors[9]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "colors = sns.dark_palette(\"#d397fa\", n_colors=10, input='rgb')\n",
    "sns.countplot(data=df, x='sentiment', palette=[colors[7], colors[9]])\n",
    "plt.xlabel(\"sentiments\", size = 12)\n",
    "plt.ylabel('Twwets', size= 12)\n",
    "plt.title(\"sentiment Disribution\", size= 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KDP-26\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\KDP-26\\AppData\\Local\\Temp\\ipykernel_8048\\2970614630.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(preprocess_text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thats bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>behaving im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0      thats bummer shoulda got david carr third day\n",
       "1  upset cant update facebook texting might cry r...\n",
       "2  dived many times ball managed save rest go bounds\n",
       "3                   whole body feels itchy like fire\n",
       "4                           behaving im mad cant see"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 1. 소문자 변환\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. URL 제거\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 3. @, # 기호 제거\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # 4. 불필요한 특수문자 제거 (단어 외의 모든 것 제거)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # 알파벳과 공백만 남기기\n",
    "    \n",
    "    # 5. 불용어 제거\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # 결과 반환 (전처리된 단어 리스트를 공백으로 연결된 문자열로 반환)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# 기존 text 열에 전처리 적용하여 덮어쓰기\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# 'processed_text' 열 제거 (만약 존재한다면)\n",
    "if 'processed_text' in df.columns:\n",
    "    df.drop(columns=['processed_text'], inplace=True)\n",
    "\n",
    "# 전처리된 데이터 확인\n",
    "df[['text']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thats bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>woke school best feeling ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>thewdbcom cool hear old walt interviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>ready mojo makeover ask details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>happy th birthday boo alll time tupac amaru sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "0                0      thats bummer shoulda got david carr third day\n",
       "1                0  upset cant update facebook texting might cry r...\n",
       "2                0  dived many times ball managed save rest go bounds\n",
       "3                0                   whole body feels itchy like fire\n",
       "4                0                           behaving im mad cant see\n",
       "...            ...                                                ...\n",
       "1599995          4                      woke school best feeling ever\n",
       "1599996          4            thewdbcom cool hear old walt interviews\n",
       "1599997          4                    ready mojo makeover ask details\n",
       "1599998          4  happy th birthday boo alll time tupac amaru sh...\n",
       "1599999          4                                              happy\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (640000, 1000), Validation: (80000, 1000), Test: (80000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋의 50%만 샘플링\n",
    "df_sampled = df.sample(frac=0.5, random_state=42)\n",
    "\n",
    "# TF-IDF 벡터화 - 희소 행렬 사용 (max_features=1000으로 줄임)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = tfidf_vectorizer.fit_transform(df_sampled['text']).toarray()\n",
    "\n",
    "# 샘플링된 데이터프레임에서 레이블 생성 (0=부정, 4=긍정)\n",
    "y = df_sampled['sentiment'].apply(lambda x: 1 if x == 4 else 0).values\n",
    "\n",
    "# 훈련 데이터, 검증 데이터, 테스트 데이터 분할 (80% 학습, 10% 검증, 10% 테스트)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 데이터 크기 확인\n",
    "print(f'Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 하이퍼파라미터 설정\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 텐서로 변환\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(DEVICE)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(DEVICE)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(DEVICE)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1).to(DEVICE)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(DEVICE)\n",
    "\n",
    "# 데이터셋 및 데이터 로더\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-26\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(1000, 512)   # 은닉층 1\n",
    "        self.bn1 = nn.BatchNorm1d(512)    # Batch Normalization 1\n",
    "        self.fc2 = nn.Linear(512, 256)    # 은닉층 2\n",
    "        self.bn2 = nn.BatchNorm1d(256)    # Batch Normalization 2\n",
    "        self.fc3 = nn.Linear(256, 128)    # 은닉층 3\n",
    "        self.bn3 = nn.BatchNorm1d(128)    # Batch Normalization 3\n",
    "        self.fc4 = nn.Linear(128, 64)     # 은닉층 4\n",
    "        self.bn4 = nn.BatchNorm1d(64)     # Batch Normalization 4\n",
    "        self.fc5 = nn.Linear(64, 1)       # 출력층: 1개의 출력 (이진 분류)\n",
    "        \n",
    "        self.relu = nn.ReLU()             # 활성화 함수 (ReLU)\n",
    "        self.sigmoid = nn.Sigmoid()       # 출력층에서 사용하는 Sigmoid (이진 분류)\n",
    "        self.dropout = nn.Dropout(p=0.3)  # Dropout (30%)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력층 -> 은닉층 1\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.bn1(x)                   # Batch Normalization 적용\n",
    "        x = self.dropout(x)               # Dropout 적용\n",
    "        \n",
    "        # 은닉층 1 -> 은닉층 2\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 은닉층 2 -> 은닉층 3\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 은닉층 3 -> 은닉층 4\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.bn4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 은닉층 4 -> 출력층\n",
    "        x = self.sigmoid(self.fc5(x))     # Sigmoid 활성화 (이진 분류)\n",
    "        return x\n",
    "# 모델, 손실 함수, 옵티마이저 설정\n",
    "model = SentimentClassifier().to(DEVICE)\n",
    "criterion = nn.BCELoss()  # 이진 분류용 손실 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 학습률 감소 스케줄러\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=100, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 0.3567173679187894\n",
      "Validation Loss: 0.6088616330862046\n",
      "Epoch 2/500, Loss: 0.3567675389289856\n",
      "Validation Loss: 0.6159947789669037\n",
      "Epoch 3/500, Loss: 0.3567366291791201\n",
      "Validation Loss: 0.6073940993785858\n",
      "Epoch 4/500, Loss: 0.35626988736093046\n",
      "Validation Loss: 0.6088369995594025\n",
      "Epoch 5/500, Loss: 0.3567305622279644\n",
      "Validation Loss: 0.6094959869146347\n",
      "Epoch 6/500, Loss: 0.35635418774336575\n",
      "Validation Loss: 0.6109939107894897\n",
      "Epoch 7/500, Loss: 0.3557797903493047\n",
      "Validation Loss: 0.6036705573081971\n",
      "Epoch 8/500, Loss: 0.35677704882621764\n",
      "Validation Loss: 0.6065786663532257\n",
      "Epoch 9/500, Loss: 0.3560342052489519\n",
      "Validation Loss: 0.6096140385389328\n",
      "Epoch 10/500, Loss: 0.3564755347728729\n",
      "Validation Loss: 0.6165626833200455\n",
      "Epoch 11/500, Loss: 0.3565856161892414\n",
      "Validation Loss: 0.606930534338951\n",
      "Epoch 12/500, Loss: 0.3562252452269197\n",
      "Validation Loss: 0.6167902674913406\n",
      "Epoch 13/500, Loss: 0.35664719423502683\n",
      "Validation Loss: 0.606360428595543\n",
      "Epoch 14/500, Loss: 0.35697649228423833\n",
      "Validation Loss: 0.6127110056161881\n",
      "Epoch 15/500, Loss: 0.3562408285290003\n",
      "Validation Loss: 0.6022086714029312\n",
      "Epoch 16/500, Loss: 0.3568050699040294\n",
      "Validation Loss: 0.6088132558584213\n",
      "Epoch 17/500, Loss: 0.35627472400963306\n",
      "Validation Loss: 0.6024355645418167\n",
      "Epoch 18/500, Loss: 0.3564926391527057\n",
      "Validation Loss: 0.6097392511606217\n",
      "Epoch 19/500, Loss: 0.35621687897592785\n",
      "Validation Loss: 0.6071281638145447\n",
      "Epoch 20/500, Loss: 0.3563208313077688\n",
      "Validation Loss: 0.6169791037321091\n",
      "Epoch 21/500, Loss: 0.3563948073416948\n",
      "Validation Loss: 0.6071981613874435\n",
      "Epoch 22/500, Loss: 0.3565527617558837\n",
      "Validation Loss: 0.6105569700717925\n",
      "Epoch 23/500, Loss: 0.3556828868955374\n",
      "Validation Loss: 0.6070576289415359\n",
      "Epoch 24/500, Loss: 0.3567255020499229\n",
      "Validation Loss: 0.6119728009462356\n",
      "Epoch 25/500, Loss: 0.35676555621623995\n",
      "Validation Loss: 0.6046759270906449\n",
      "Epoch 26/500, Loss: 0.3566800982385874\n",
      "Validation Loss: 0.6122599677801133\n",
      "Epoch 27/500, Loss: 0.35737280296832324\n",
      "Validation Loss: 0.6055358619451523\n",
      "Epoch 28/500, Loss: 0.35664146780371664\n",
      "Validation Loss: 0.6139964043140411\n",
      "Epoch 29/500, Loss: 0.3565057614311576\n",
      "Validation Loss: 0.6048316886425018\n",
      "Epoch 30/500, Loss: 0.356557089689374\n",
      "Validation Loss: 0.6047204382419586\n",
      "Epoch 31/500, Loss: 0.35642738468050955\n",
      "Validation Loss: 0.6103284899234772\n",
      "Epoch 32/500, Loss: 0.35637292469888926\n",
      "Validation Loss: 0.6069563019752502\n",
      "Epoch 33/500, Loss: 0.35616203071922065\n",
      "Validation Loss: 0.6065321116685868\n",
      "Epoch 34/500, Loss: 0.357262035356462\n",
      "Validation Loss: 0.6160855923175812\n",
      "Epoch 35/500, Loss: 0.3571225105121732\n",
      "Validation Loss: 0.6127873765945434\n",
      "Epoch 36/500, Loss: 0.35718252867758277\n",
      "Validation Loss: 0.614537430524826\n",
      "Epoch 37/500, Loss: 0.3560219994366169\n",
      "Validation Loss: 0.606651834487915\n",
      "Epoch 38/500, Loss: 0.3563888312965631\n",
      "Validation Loss: 0.6035408600568771\n",
      "Epoch 39/500, Loss: 0.35658071816414594\n",
      "Validation Loss: 0.6073281537294388\n",
      "Epoch 40/500, Loss: 0.3570963926568627\n",
      "Validation Loss: 0.6072831818580627\n",
      "Epoch 41/500, Loss: 0.35603641392588614\n",
      "Validation Loss: 0.6101288606882095\n",
      "Epoch 42/500, Loss: 0.3557872755870223\n",
      "Validation Loss: 0.6122914444446563\n",
      "Epoch 43/500, Loss: 0.3560499192237854\n",
      "Validation Loss: 0.6060397049665451\n",
      "Epoch 44/500, Loss: 0.35722664539217946\n",
      "Validation Loss: 0.6093008664131164\n",
      "Epoch 45/500, Loss: 0.3563705227032304\n",
      "Validation Loss: 0.6080556272268295\n",
      "Epoch 46/500, Loss: 0.35700843853503467\n",
      "Validation Loss: 0.6081649194002151\n",
      "Epoch 47/500, Loss: 0.3565308398038149\n",
      "Validation Loss: 0.6128100928544998\n",
      "Epoch 48/500, Loss: 0.3567523554816842\n",
      "Validation Loss: 0.603982626247406\n",
      "Epoch 49/500, Loss: 0.35675273428708315\n",
      "Validation Loss: 0.612750210404396\n",
      "Epoch 50/500, Loss: 0.3567631909966469\n",
      "Validation Loss: 0.614227737569809\n",
      "Epoch 51/500, Loss: 0.35635680898875\n",
      "Validation Loss: 0.6151090399980546\n",
      "Epoch 52/500, Loss: 0.35650299051254986\n",
      "Validation Loss: 0.6126366663455963\n",
      "Epoch 53/500, Loss: 0.35681784902513025\n",
      "Validation Loss: 0.60766872382164\n",
      "Epoch 54/500, Loss: 0.35668236878812315\n",
      "Validation Loss: 0.6170505710840225\n",
      "Epoch 55/500, Loss: 0.35690268223434685\n",
      "Validation Loss: 0.6122876792907714\n",
      "Epoch 56/500, Loss: 0.3563428159803152\n",
      "Validation Loss: 0.6120228473663331\n",
      "Epoch 57/500, Loss: 0.35663326523154976\n",
      "Validation Loss: 0.608813688158989\n",
      "Epoch 58/500, Loss: 0.35695350519567726\n",
      "Validation Loss: 0.6129484208583832\n",
      "Epoch 59/500, Loss: 0.3563797648027539\n",
      "Validation Loss: 0.6146294100761414\n",
      "Epoch 60/500, Loss: 0.3559228489518166\n",
      "Validation Loss: 0.616612417268753\n",
      "Epoch 61/500, Loss: 0.35645687300562856\n",
      "Validation Loss: 0.6160696003198624\n",
      "Epoch 62/500, Loss: 0.3564782769292593\n",
      "Validation Loss: 0.6099519706249237\n",
      "Epoch 63/500, Loss: 0.35631923974603413\n",
      "Validation Loss: 0.6086194753408432\n",
      "Epoch 64/500, Loss: 0.35643739532381297\n",
      "Validation Loss: 0.6036455312728882\n",
      "Epoch 65/500, Loss: 0.3572438172698021\n",
      "Validation Loss: 0.6048970273017883\n",
      "Epoch 66/500, Loss: 0.35641619469076397\n",
      "Validation Loss: 0.6123133468627929\n",
      "Epoch 67/500, Loss: 0.35582529012709857\n",
      "Validation Loss: 0.6164656697273254\n",
      "Epoch 68/500, Loss: 0.3565858369410038\n",
      "Validation Loss: 0.6069467139244079\n",
      "Epoch 69/500, Loss: 0.35629449488669634\n",
      "Validation Loss: 0.6059646280765534\n",
      "Epoch 70/500, Loss: 0.3570866419017315\n",
      "Validation Loss: 0.6108439210176468\n",
      "Epoch 71/500, Loss: 0.3569224918797612\n",
      "Validation Loss: 0.6071296401262284\n",
      "Epoch 72/500, Loss: 0.35609800754785537\n",
      "Validation Loss: 0.6180501194477082\n",
      "Epoch 73/500, Loss: 0.356306346142292\n",
      "Validation Loss: 0.613571911072731\n",
      "Epoch 74/500, Loss: 0.3558505937486887\n",
      "Validation Loss: 0.6060151373147964\n",
      "Epoch 75/500, Loss: 0.3564669862985611\n",
      "Validation Loss: 0.6131221425771713\n",
      "Epoch 76/500, Loss: 0.3557374644488096\n",
      "Validation Loss: 0.6047090183258057\n",
      "Epoch 77/500, Loss: 0.35677211430072786\n",
      "Validation Loss: 0.6169883570194244\n",
      "Epoch 78/500, Loss: 0.3563288414463401\n",
      "Validation Loss: 0.6086289563655853\n",
      "Epoch 79/500, Loss: 0.3563958023741841\n",
      "Validation Loss: 0.6142410144090652\n",
      "Epoch 80/500, Loss: 0.3563988026693463\n",
      "Validation Loss: 0.6087583966970443\n",
      "Epoch 81/500, Loss: 0.35621554007977246\n",
      "Validation Loss: 0.6036313244819641\n",
      "Epoch 82/500, Loss: 0.35559121090471746\n",
      "Validation Loss: 0.6123416559457779\n",
      "Epoch 83/500, Loss: 0.35686367479115727\n",
      "Validation Loss: 0.6090114041805267\n",
      "Epoch 84/500, Loss: 0.35695107450783253\n",
      "Validation Loss: 0.6098297466039657\n",
      "Epoch 85/500, Loss: 0.3565939253628254\n",
      "Validation Loss: 0.6101027692794799\n",
      "Epoch 86/500, Loss: 0.3565724704191089\n",
      "Validation Loss: 0.6061627242326737\n",
      "Epoch 87/500, Loss: 0.35595420802384614\n",
      "Validation Loss: 0.6138369043111801\n",
      "Epoch 88/500, Loss: 0.3562070502266288\n",
      "Validation Loss: 0.6084367175102234\n",
      "Epoch 89/500, Loss: 0.35660182763785125\n",
      "Validation Loss: 0.6135611358404159\n",
      "Epoch 90/500, Loss: 0.3563373081579804\n",
      "Validation Loss: 0.6188365880250931\n",
      "Epoch 91/500, Loss: 0.3567294062167406\n",
      "Validation Loss: 0.6055602462053299\n",
      "Epoch 92/500, Loss: 0.3568997779160738\n",
      "Validation Loss: 0.6176417127132415\n",
      "Epoch 93/500, Loss: 0.3562250536620617\n",
      "Validation Loss: 0.6115405358076096\n",
      "Epoch 94/500, Loss: 0.3567389425113797\n",
      "Validation Loss: 0.6125677000999451\n",
      "Epoch 95/500, Loss: 0.35526862372159956\n",
      "Validation Loss: 0.6179294362783432\n",
      "Epoch 96/500, Loss: 0.35641838816553356\n",
      "Validation Loss: 0.6106394191741943\n",
      "Epoch 97/500, Loss: 0.3566822936922312\n",
      "Validation Loss: 0.6185304905653\n",
      "Epoch 98/500, Loss: 0.35615487379133703\n",
      "Validation Loss: 0.6105083867549896\n",
      "Epoch 99/500, Loss: 0.35652654095143077\n",
      "Validation Loss: 0.6107978910923004\n",
      "Epoch 100/500, Loss: 0.35646604031324386\n",
      "Validation Loss: 0.6142448603153229\n",
      "Epoch 101/500, Loss: 0.357298765052855\n",
      "Validation Loss: 0.5979456590414047\n",
      "Epoch 102/500, Loss: 0.35699099437892434\n",
      "Validation Loss: 0.6090787971735001\n",
      "Epoch 103/500, Loss: 0.3560788276836276\n",
      "Validation Loss: 0.6089761014699936\n",
      "Epoch 104/500, Loss: 0.356398409435153\n",
      "Validation Loss: 0.6104331192731858\n",
      "Epoch 105/500, Loss: 0.35687390785813333\n",
      "Validation Loss: 0.6117459740161896\n",
      "Epoch 106/500, Loss: 0.35680809945464137\n",
      "Validation Loss: 0.6071381151199341\n",
      "Epoch 107/500, Loss: 0.3563089834079146\n",
      "Validation Loss: 0.606453118777275\n",
      "Epoch 108/500, Loss: 0.35607949879914524\n",
      "Validation Loss: 0.6162043574333191\n",
      "Epoch 109/500, Loss: 0.3560908031836152\n",
      "Validation Loss: 0.6177462096691132\n",
      "Epoch 110/500, Loss: 0.35642905001342295\n",
      "Validation Loss: 0.6116476560592652\n",
      "Epoch 111/500, Loss: 0.3566683045402169\n",
      "Validation Loss: 0.6075739300966263\n",
      "Epoch 112/500, Loss: 0.35610575067102906\n",
      "Validation Loss: 0.6068957226753234\n",
      "Epoch 113/500, Loss: 0.3567186561435461\n",
      "Validation Loss: 0.6101962837219238\n",
      "Epoch 114/500, Loss: 0.356285507838428\n",
      "Validation Loss: 0.6098300107240677\n",
      "Epoch 115/500, Loss: 0.3567606321245432\n",
      "Validation Loss: 0.6068213522672653\n",
      "Epoch 116/500, Loss: 0.356382564021647\n",
      "Validation Loss: 0.6176851178884506\n",
      "Epoch 117/500, Loss: 0.3569459870889783\n",
      "Validation Loss: 0.6077214038848877\n",
      "Epoch 118/500, Loss: 0.35620503464341163\n",
      "Validation Loss: 0.6134710944652557\n",
      "Epoch 119/500, Loss: 0.35590483382344246\n",
      "Validation Loss: 0.6116858440876007\n",
      "Epoch 120/500, Loss: 0.3571981689706445\n",
      "Validation Loss: 0.6127401939153672\n",
      "Epoch 121/500, Loss: 0.3559507841736078\n",
      "Validation Loss: 0.5983343258619308\n",
      "Epoch 122/500, Loss: 0.356400343991816\n",
      "Validation Loss: 0.6140287278890609\n",
      "Epoch 123/500, Loss: 0.3564367603629828\n",
      "Validation Loss: 0.6190378484964371\n",
      "Epoch 124/500, Loss: 0.356923771712184\n",
      "Validation Loss: 0.6139614485025406\n",
      "Epoch 125/500, Loss: 0.35625594531595706\n",
      "Validation Loss: 0.6087299034118653\n",
      "Epoch 126/500, Loss: 0.35661225600242613\n",
      "Validation Loss: 0.6101667796373367\n",
      "Epoch 127/500, Loss: 0.3558929308325052\n",
      "Validation Loss: 0.6238199355125428\n",
      "Epoch 128/500, Loss: 0.35723187868595124\n",
      "Validation Loss: 0.6052782047271729\n",
      "Epoch 129/500, Loss: 0.3556602555140853\n",
      "Validation Loss: 0.6120243633270264\n",
      "Epoch 130/500, Loss: 0.3563418945252895\n",
      "Validation Loss: 0.614687843632698\n",
      "Epoch 131/500, Loss: 0.35633676269203424\n",
      "Validation Loss: 0.6059101737499237\n",
      "Epoch 132/500, Loss: 0.35691626323461534\n",
      "Validation Loss: 0.6148633813858032\n",
      "Epoch 133/500, Loss: 0.35660928628295663\n",
      "Validation Loss: 0.6064105406522751\n",
      "Epoch 134/500, Loss: 0.3566059671506286\n",
      "Validation Loss: 0.6144023066520691\n",
      "Epoch 135/500, Loss: 0.356558543074131\n",
      "Validation Loss: 0.6073897538900376\n",
      "Epoch 136/500, Loss: 0.35666500248759986\n",
      "Validation Loss: 0.608439650940895\n",
      "Epoch 137/500, Loss: 0.35706311979293825\n",
      "Validation Loss: 0.6137024791240692\n",
      "Epoch 138/500, Loss: 0.3568800358101726\n",
      "Validation Loss: 0.6202935637950897\n",
      "Epoch 139/500, Loss: 0.3572347665682435\n",
      "Validation Loss: 0.6136146613121033\n",
      "Epoch 140/500, Loss: 0.35689305509328845\n",
      "Validation Loss: 0.6104399174928665\n",
      "Epoch 141/500, Loss: 0.35679266861975195\n",
      "Validation Loss: 0.6070891288995742\n",
      "Epoch 142/500, Loss: 0.35660921469330786\n",
      "Validation Loss: 0.605755814409256\n",
      "Epoch 143/500, Loss: 0.3568987898886204\n",
      "Validation Loss: 0.616772623038292\n",
      "Epoch 144/500, Loss: 0.35731017629802225\n",
      "Validation Loss: 0.6180961778879166\n",
      "Epoch 145/500, Loss: 0.3565961784556508\n",
      "Validation Loss: 0.619572019124031\n",
      "Epoch 146/500, Loss: 0.35627034284323456\n",
      "Validation Loss: 0.6083191775083542\n",
      "Epoch 147/500, Loss: 0.3565757804587483\n",
      "Validation Loss: 0.6074811653614044\n",
      "Epoch 148/500, Loss: 0.35603593601435424\n",
      "Validation Loss: 0.6101496260881424\n",
      "Epoch 149/500, Loss: 0.3566205903545022\n",
      "Validation Loss: 0.6106618292570114\n",
      "Epoch 150/500, Loss: 0.35587000639885663\n",
      "Validation Loss: 0.6155591784954071\n",
      "Epoch 151/500, Loss: 0.3565048228785396\n",
      "Validation Loss: 0.6094009150266647\n",
      "Epoch 152/500, Loss: 0.35608776502907274\n",
      "Validation Loss: 0.6178967622756958\n",
      "Epoch 153/500, Loss: 0.35573599053770305\n",
      "Validation Loss: 0.6064501387596131\n",
      "Epoch 154/500, Loss: 0.356169162081182\n",
      "Validation Loss: 0.6140202344894409\n",
      "Epoch 155/500, Loss: 0.3561259987786412\n",
      "Validation Loss: 0.6110710886716842\n",
      "Epoch 156/500, Loss: 0.35621710566580295\n",
      "Validation Loss: 0.605108655500412\n",
      "Epoch 157/500, Loss: 0.3571061514109373\n",
      "Validation Loss: 0.6149579771518707\n",
      "Epoch 158/500, Loss: 0.3557487868860364\n",
      "Validation Loss: 0.6009770390748977\n",
      "Epoch 159/500, Loss: 0.35644920964837074\n",
      "Validation Loss: 0.6179471554279328\n",
      "Epoch 160/500, Loss: 0.35680191969275477\n",
      "Validation Loss: 0.6121426005363464\n",
      "Epoch 161/500, Loss: 0.356129231891036\n",
      "Validation Loss: 0.6174161277294159\n",
      "Epoch 162/500, Loss: 0.3561298117592931\n",
      "Validation Loss: 0.6093766552448273\n",
      "Epoch 163/500, Loss: 0.35612182802557946\n",
      "Validation Loss: 0.6099848745584487\n",
      "Epoch 164/500, Loss: 0.3569700951263309\n",
      "Validation Loss: 0.6136641182899475\n",
      "Epoch 165/500, Loss: 0.35638475060164926\n",
      "Validation Loss: 0.6023385254144669\n",
      "Epoch 166/500, Loss: 0.3562890933662653\n",
      "Validation Loss: 0.6136262939453125\n",
      "Epoch 167/500, Loss: 0.35623612891435624\n",
      "Validation Loss: 0.600295354604721\n",
      "Epoch 168/500, Loss: 0.35643236380517485\n",
      "Validation Loss: 0.6053259922504425\n",
      "Epoch 169/500, Loss: 0.3572079284086824\n",
      "Validation Loss: 0.6069539478063584\n",
      "Epoch 170/500, Loss: 0.35713400155752895\n",
      "Validation Loss: 0.6030328227758408\n",
      "Epoch 171/500, Loss: 0.3569713596493006\n",
      "Validation Loss: 0.6109231637954712\n",
      "Epoch 172/500, Loss: 0.356297051101923\n",
      "Validation Loss: 0.613054458451271\n",
      "Epoch 173/500, Loss: 0.356248416416347\n",
      "Validation Loss: 0.6043649851083756\n",
      "Epoch 174/500, Loss: 0.3560820180296898\n",
      "Validation Loss: 0.6123097126483917\n",
      "Epoch 175/500, Loss: 0.35678643566966056\n",
      "Validation Loss: 0.6100213866472244\n",
      "Epoch 176/500, Loss: 0.35590693826824427\n",
      "Validation Loss: 0.6111493897676468\n",
      "Epoch 177/500, Loss: 0.35714867011606694\n",
      "Validation Loss: 0.6218955627441406\n",
      "Epoch 178/500, Loss: 0.3562648808866739\n",
      "Validation Loss: 0.6154056423425674\n",
      "Epoch 179/500, Loss: 0.35684525515586135\n",
      "Validation Loss: 0.6063361231565475\n",
      "Epoch 180/500, Loss: 0.3570537335216999\n",
      "Validation Loss: 0.6136980831623078\n",
      "Epoch 181/500, Loss: 0.35626779754906895\n",
      "Validation Loss: 0.6060148755788803\n",
      "Epoch 182/500, Loss: 0.3569178516611457\n",
      "Validation Loss: 0.6127583385705948\n",
      "Epoch 183/500, Loss: 0.3564692666977644\n",
      "Validation Loss: 0.611194215798378\n",
      "Epoch 184/500, Loss: 0.3565648394301534\n",
      "Validation Loss: 0.6189728940010071\n",
      "Epoch 185/500, Loss: 0.356891556635499\n",
      "Validation Loss: 0.6054926465272903\n",
      "Epoch 186/500, Loss: 0.3572743372052908\n",
      "Validation Loss: 0.6171637969732284\n",
      "Epoch 187/500, Loss: 0.35564514016211035\n",
      "Validation Loss: 0.6038998935461044\n",
      "Epoch 188/500, Loss: 0.35744198900312185\n",
      "Validation Loss: 0.6067328972578049\n",
      "Epoch 189/500, Loss: 0.35669839433282613\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_loss\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[90], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 검증\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Early Stopping 체크\u001b[39;00m\n\u001b[0;32m     24\u001b[0m early_stopping(val_loss)\n",
      "Cell \u001b[1;32mIn[90], line 36\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, val_loader)\u001b[0m\n\u001b[0;32m     34\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m     37\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     38\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\KDP-26\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:642\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    638\u001b[0m         warn_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor multiprocessing data-loading, this could be caused by not properly configuring the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    639\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterableDataset replica at each worker. Please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    640\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    641\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(warn_msg)\n\u001b[1;32m--> 642\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\KDP-26\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\autograd\\profiler.py:705\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m--> 705\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_exit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    707\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[1;32mc:\\Users\\KDP-26\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\_ops.py:903\u001b[0m, in \u001b[0;36mTorchBindOpOverload.__call__\u001b[1;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_register_as_effectful_op_temporarily():\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_dispatch_in_python(\n\u001b[0;32m    901\u001b[0m             args, kwargs, self_\u001b[38;5;241m.\u001b[39m_fallthrough_keys()\n\u001b[0;32m    902\u001b[0m         )\n\u001b[1;32m--> 903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 및 검증 과정\n",
    "early_stopping = EarlyStopping(patience=100)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=EPOCHS):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "        \n",
    "        # 검증\n",
    "        val_loss = validate_model(model, val_loader)\n",
    "        \n",
    "        # Early Stopping 체크\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss/len(val_loader)}\")\n",
    "    return val_loss\n",
    "\n",
    "# 모델 학습\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.33%\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가 과정\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs >= 0.5).float()  # 0.5 이상의 값은 긍정으로 분류\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 모델 평가\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-26\\AppData\\Local\\Temp\\ipykernel_8048\\1177920183.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_weights.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (fc1): Linear(in_features=1000, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc5): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 모델 저장\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "\n",
    "# 모델 로드\n",
    "model = SentimentClassifier()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()  # 평가 모드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-26\\AppData\\Local\\Temp\\ipykernel_8048\\3079592399.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_weights.pth'))  # 저장된 가중치 불러오기\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력하신 단어나 문장은 Negative입니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 학습된 모델 불러오기\n",
    "model = SentimentClassifier()  # 동일한 모델 구조\n",
    "model.load_state_dict(torch.load('model_weights.pth'))  # 저장된 가중치 불러오기\n",
    "model.eval()  # 평가 모드로 전환\n",
    "\n",
    "# TF-IDF 벡터화 도구 불러오기\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf_vectorizer.fit(df_sampled['text'])  # 기존 데이터로 벡터라이저 학습\n",
    "\n",
    "def predict_sentiment(model, text, vectorizer, threshold=0.69):\n",
    "    # 입력된 텍스트를 벡터화 (TF-IDF 또는 다른 벡터화 방식 사용)\n",
    "    input_vector = vectorizer.transform([text]).toarray()  # 문장을 벡터화\n",
    "    input_tensor = torch.tensor(input_vector, dtype=torch.float32)  # 텐서로 변환\n",
    "\n",
    "    # 모델로 예측 수행\n",
    "    with torch.no_grad():  # 기울기 계산 불필요\n",
    "        output = model(input_tensor)\n",
    "        prediction = torch.sigmoid(output)  # 이진 분류이므로 Sigmoid 사용\n",
    "        predicted_label = (prediction >= threshold).item()  # 0.5 이상이면 긍정\n",
    "\n",
    "    # 예측 결과 반환 (Positive 또는 Negative)\n",
    "    return 'Positive' if predicted_label == 1 else 'Negative'\n",
    "\n",
    "# 사용 예시\n",
    "text_input = 'fuck you '\n",
    "result = predict_sentiment(model, text_input, tfidf_vectorizer)\n",
    "print(f\"입력하신 단어나 문장은 {result}입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
